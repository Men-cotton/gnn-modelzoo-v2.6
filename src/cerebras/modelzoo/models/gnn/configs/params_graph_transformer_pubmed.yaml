trainer:
  init:
    model_dir: ./model_dir_gnn
    seed: 42
    model:
      name: gnn

      # GNN Architecture parameters
      n_feat: 500 # PubMed: Dimensionality of node features
      n_class: 3 # PubMed: Number of classes
      n_hid: 16 # Hidden dimension for the GraphTransformer

      # GNNModel wrapper parameters
      compute_eval_metrics: True
      disable_log_softmax: False
      core_architecture: GraphTransformer
      # GraphTransformer specific parameters
      gt_num_layers: 2
      gt_heads: 2
      gt_dropout: 0.5

      # Unused GraphSAGE parameters
      graphsage_hidden_dim: 128
      graphsage_num_layers: 2
      graphsage_dropout: 0.5
      graphsage_aggregator: mean

    optimizer:
      AdamW:
        params: []
        learning_rate: 0.01
        weight_decay: 0.0005

    precision:
      enabled: True
      fp16_type: "float16"
      loss_scaling_factor: "dynamic"

    loop:
      max_steps: 200
      steps_per_epoch: 1
      eval_frequency: 10

    logging:
      log_steps: 1

  fit:
    train_dataloader:
      data_processor: GNNDataProcessor
      dataset_name: PubMed
      data_dir: src/cerebras/modelzoo/models/gnn/data/datasets/
      sampling_mode: neighbor
      fanouts: [25, 10]
      batch_size: 16
      drop_last_batch: False
      shuffle: True
      num_workers: 0
      sampler_seed: 42
      split: train

    val_dataloader: &val_dataloader_params
      data_processor: GNNDataProcessor
      dataset_name: PubMed
      data_dir: ./data/datasets/
      sampling_mode: neighbor
      fanouts: [25, 10]
      batch_size: 64
      drop_last_batch: False
      shuffle: False
      num_workers: 0
      sampler_seed: 42
      split: val

  validate:
    val_dataloader: *val_dataloader_params

  validate_all:
    val_dataloaders:
      - *val_dataloader_params

runconfig:
  python_paths:
    - src
